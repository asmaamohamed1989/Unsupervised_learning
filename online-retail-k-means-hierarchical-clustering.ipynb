{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a id=\"1\"></a> <br>\n","## Step 1 : Reading and Understanding Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import required libraries for dataframe and visualization\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import datetime as dt\n","\n","# import required libraries for clustering\n","import sklearn\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","from scipy.cluster.hierarchy import linkage\n","from scipy.cluster.hierarchy import dendrogram\n","from scipy.cluster.hierarchy import cut_tree"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Reading the data on which analysis needs to be done\n","\n","retail = pd.read_csv('../input/online-retail-customer-clustering/OnlineRetail.csv', sep=\",\", encoding=\"ISO-8859-1\", header=0)\n","retail.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# shape of df\n","\n","retail.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# df info\n","\n","retail.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# df description\n","\n","retail.describe()"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"2\"></a> <br>\n","## Step 2 : Data Cleansing"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Calculating the Missing Values % contribution in DF\n","\n","df_null = round(100*(retail.isnull().sum())/len(retail), 2)\n","df_null"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Droping rows having missing values\n","\n","retail = retail.dropna()\n","retail.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Changing the datatype of Customer Id as per Business understanding\n","\n","retail['CustomerID'] = retail['CustomerID'].astype(str)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"3\"></a> <br>\n","## Step 3 : Data Preparation"]},{"cell_type":"markdown","metadata":{},"source":["#### We are going to analysis the Customers based on below 3 factors:\n","- R (Recency): Number of days since last purchase\n","- F (Frequency): Number of tracsactions\n","- M (Monetary): Total amount of transactions (revenue contributed)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# New Attribute : Monetary\n","\n","retail['Amount'] = retail['Quantity']*retail['UnitPrice']\n","rfm_m = retail.groupby('CustomerID')['Amount'].sum()\n","rfm_m = rfm_m.reset_index()\n","rfm_m.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# New Attribute : Frequency\n","\n","rfm_f = retail.groupby('CustomerID')['InvoiceNo'].count()\n","rfm_f = rfm_f.reset_index()\n","rfm_f.columns = ['CustomerID', 'Frequency']\n","rfm_f.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["# Merging the two dfs\n","\n","rfm = pd.merge(rfm_m, rfm_f, on='CustomerID', how='inner')\n","rfm.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# New Attribute : Recency\n","\n","# Convert to datetime to proper datatype\n","\n","retail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Compute the maximum date to know the last transaction date\n","\n","max_date = max(retail['InvoiceDate'])\n","max_date"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Compute the difference between max date and transaction date\n","\n","retail['Diff'] = max_date - retail['InvoiceDate']\n","retail.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Compute last transaction date to get the recency of customers\n","\n","rfm_p = retail.groupby('CustomerID')['Diff'].min()\n","rfm_p = rfm_p.reset_index()\n","rfm_p.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Extract number of days only\n","\n","rfm_p['Diff'] = rfm_p['Diff'].dt.days\n","rfm_p.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Merge tha dataframes to get the final RFM dataframe\n","\n","rfm = pd.merge(rfm, rfm_p, on='CustomerID', how='inner')\n","rfm.columns = ['CustomerID', 'Amount', 'Frequency', 'Recency']\n","rfm.head()"]},{"cell_type":"markdown","metadata":{},"source":["#### There are 2 types of outliers and we will treat outliers as it can skew our dataset\n","- Statistical\n","- Domain specific"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Outlier Analysis of Amount Frequency and Recency\n","\n","attributes = ['Amount','Frequency','Recency']\n","plt.rcParams['figure.figsize'] = [10,8]\n","sns.boxplot(data = rfm[attributes], orient=\"v\", palette=\"Set2\" ,whis=1.5,saturation=1, width=0.7)\n","plt.title(\"Outliers Variable Distribution\", fontsize = 14, fontweight = 'bold')\n","plt.ylabel(\"Range\", fontweight = 'bold')\n","plt.xlabel(\"Attributes\", fontweight = 'bold')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Removing (statistical) outliers for Amount\n","Q1 = rfm.Amount.quantile(0.05)\n","Q3 = rfm.Amount.quantile(0.95)\n","IQR = Q3 - Q1\n","rfm = rfm[(rfm.Amount >= Q1 - 1.5*IQR) & (rfm.Amount <= Q3 + 1.5*IQR)]\n","\n","# Removing (statistical) outliers for Recency\n","Q1 = rfm.Recency.quantile(0.05)\n","Q3 = rfm.Recency.quantile(0.95)\n","IQR = Q3 - Q1\n","rfm = rfm[(rfm.Recency >= Q1 - 1.5*IQR) & (rfm.Recency <= Q3 + 1.5*IQR)]\n","\n","# Removing (statistical) outliers for Frequency\n","Q1 = rfm.Frequency.quantile(0.05)\n","Q3 = rfm.Frequency.quantile(0.95)\n","IQR = Q3 - Q1\n","rfm = rfm[(rfm.Frequency >= Q1 - 1.5*IQR) & (rfm.Frequency <= Q3 + 1.5*IQR)]"]},{"cell_type":"markdown","metadata":{},"source":["### Rescaling the Attributes\n","\n","It is extremely important to rescale the variables so that they have a comparable scale.|\n","There are two common ways of rescaling:\n","\n","1. Min-Max scaling \n","2. Standardisation (mean-0, sigma-1) \n","\n","Here, we will use Standardisation Scaling."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Rescaling the attributes\n","\n","rfm_df = rfm[['Amount', 'Frequency', 'Recency']]\n","\n","# Instantiate\n","scaler = StandardScaler()\n","\n","# fit_transform\n","rfm_df_scaled = scaler.fit_transform(rfm_df)\n","rfm_df_scaled.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rfm_df_scaled = pd.DataFrame(rfm_df_scaled)\n","rfm_df_scaled.columns = ['Amount', 'Frequency', 'Recency']\n","rfm_df_scaled.head()"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"4\"></a> <br>\n","## Step 4 : Building the Model"]},{"cell_type":"markdown","metadata":{},"source":["### K-Means Clustering"]},{"cell_type":"markdown","metadata":{},"source":["K-means clustering is one of the simplest and popular unsupervised machine learning algorithms.<br>\n","\n","The algorithm works as follows:\n","\n","- First we initialize k points, called means, randomly.\n","- We categorize each item to its closest mean and we update the mean’s coordinates, which are the averages of the items categorized in that mean so far.\n","- We repeat the process for a given number of iterations and at the end, we have our clusters."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# k-means with some arbitrary k\n","\n","kmeans = KMeans(n_clusters=4, max_iter=50)\n","kmeans.fit(rfm_df_scaled)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["kmeans.labels_"]},{"cell_type":"markdown","metadata":{},"source":["### Finding the Optimal Number of Clusters"]},{"cell_type":"markdown","metadata":{},"source":["#### Elbow Curve to get the right number of Clusters\n","A fundamental step for any unsupervised algorithm is to determine the optimal number of clusters into which the data may be clustered. The Elbow Method is one of the most popular methods to determine this optimal value of k."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Elbow-curve/SSD\n","\n","ssd = []\n","range_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n","for num_clusters in range_n_clusters:\n","    kmeans = KMeans(n_clusters=num_clusters, max_iter=50)\n","    kmeans.fit(rfm_df_scaled)\n","    \n","    ssd.append(kmeans.inertia_)\n","    \n","# plot the SSDs for each n_clusters\n","plt.plot(ssd)"]},{"cell_type":"markdown","metadata":{},"source":["### Silhouette Analysis\n","\n","$$\\text{silhouette score}=\\frac{p-q}{max(p,q)}$$\n","\n","$p$ is the mean distance to the points in the nearest cluster that the data point is not a part of\n","\n","$q$ is the mean intra-cluster distance to all the points in its own cluster.\n","\n","* The value of the silhouette score range lies between -1 to 1. \n","\n","* A score closer to 1 indicates that the data point is very similar to other data points in the cluster, \n","\n","* A score closer to -1 indicates that the data point is not similar to the data points in its cluster."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Silhouette analysis\n","range_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n","\n","for num_clusters in range_n_clusters:\n","    \n","    # intialise kmeans\n","    kmeans = KMeans(n_clusters=num_clusters, max_iter=50)\n","    kmeans.fit(rfm_df_scaled)\n","    \n","    cluster_labels = kmeans.labels_\n","    \n","    # silhouette score\n","    silhouette_avg = silhouette_score(rfm_df_scaled, cluster_labels)\n","    print(\"For n_clusters={0}, the silhouette score is {1}\".format(num_clusters, silhouette_avg))\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Final model with k=3\n","kmeans = KMeans(n_clusters=3, max_iter=50)\n","kmeans.fit(rfm_df_scaled)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[" kmeans.labels_"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# assign the label\n","rfm['Cluster_Id'] = kmeans.labels_\n","rfm.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Box plot to visualize Cluster Id vs Frequency\n","\n","sns.boxplot(x='Cluster_Id', y='Amount', data=rfm)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Box plot to visualize Cluster Id vs Frequency\n","\n","sns.boxplot(x='Cluster_Id', y='Frequency', data=rfm)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Box plot to visualize Cluster Id vs Recency\n","\n","sns.boxplot(x='Cluster_Id', y='Recency', data=rfm)"]},{"cell_type":"markdown","metadata":{},"source":["### Hierarchical Clustering\n","\n","Hierarchical clustering involves creating clusters that have a predetermined ordering from top to bottom. For example, all files and folders on the hard disk are organized in a hierarchy. There are two types of hierarchical clustering, \n","- Divisive \n","- Agglomerative."]},{"cell_type":"markdown","metadata":{},"source":["**Single Linkage:<br>**\n","\n","In single linkage hierarchical clustering, the distance between two clusters is defined as the shortest distance between two points in each cluster. For example, the distance between clusters “r” and “s” to the left is equal to the length of the arrow between their two closest points.\n","![](https://www.saedsayad.com/images/Clustering_single.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Single linkage: \n","\n","mergings = linkage(rfm_df_scaled, method=\"single\", metric='euclidean')\n","dendrogram(mergings)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Complete Linkage<br>**\n","\n","In complete linkage hierarchical clustering, the distance between two clusters is defined as the longest distance between two points in each cluster. For example, the distance between clusters “r” and “s” to the left is equal to the length of the arrow between their two furthest points. \n","![](https://www.saedsayad.com/images/Clustering_complete.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Complete linkage\n","\n","mergings = linkage(rfm_df_scaled, method=\"complete\", metric='euclidean')\n","dendrogram(mergings)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Average Linkage:<br>**\n","\n","In average linkage hierarchical clustering, the distance between two clusters is defined as the average distance between each point in one cluster to every point in the other cluster. For example, the distance between clusters “r” and “s” to the left is equal to the average length each arrow between connecting the points of one cluster to the other.\n","![](https://www.saedsayad.com/images/Clustering_average.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Average linkage\n","\n","mergings = linkage(rfm_df_scaled, method=\"average\", metric='euclidean')\n","dendrogram(mergings)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Cutting the Dendrogram based on K"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 3 clusters\n","cluster_labels = cut_tree(mergings, n_clusters=3).reshape(-1, )\n","cluster_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Assign cluster labels\n","\n","rfm['Cluster_Labels'] = cluster_labels\n","rfm.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot Cluster Id vs Amount\n","\n","sns.boxplot(x='Cluster_Labels', y='Amount', data=rfm)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot Cluster Id vs Frequency\n","\n","sns.boxplot(x='Cluster_Labels', y='Frequency', data=rfm)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot Cluster Id vs Recency\n","\n","sns.boxplot(x='Cluster_Labels', y='Recency', data=rfm)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"5\"></a> <br>\n","## Step 5 : Final Analysis"]},{"cell_type":"markdown","metadata":{},"source":["### Inference:\n","K-Means Clustering with 3 Cluster Ids\n","- Customers with Cluster Id 1 are the customers with high amount of transactions as compared to other customers.\n","- Customers with Cluster Id 1 are frequent buyers.\n","- Customers with Cluster Id 2 are not recent buyers and hence least of importance from business point of view."]},{"cell_type":"markdown","metadata":{},"source":["Hierarchical Clustering with 3 Cluster Labels\n","- Customers with Cluster_Labels 2 are the customers with high amount of transactions as compared to other customers.\n","- Customers with Cluster_Labels 2 are frequent buyers.\n","- Customers with Cluster_Labels 0 are not recent buyers and hence least of importance from business point of view."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}
